{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tehtävä 1.\n",
    "## Aihe: Uutisotsikon klassifiointi - Clickbait vai ei?\n",
    "2,5 pistettä\n",
    "\n",
    "Datasetti:\n",
    "https://github.com/bhargaviparanjape/clickbait/tree/master/dataset\n",
    "\n",
    "1. Lataa clickbait ja ei-clickbait otsikot clickbait_data.txt ja non_clickbait_data.txt tiedostoista data - kansiosta\n",
    "2. Leimaa otsikot 0 tai 1 luokkaan (clickbait vai ei)\n",
    "2. Jaa data koulutus- ja testidataan (80% koulutusdataa 20% testidataa jako)\n",
    "4. Luo RNN - malli, joka ennustaa, onko otsikko clickbait vai ei\n",
    "5. Tulosta mallin tarkkuus evaluate - funktiolla\n",
    "6. Aja \"Tehtävän vastaukset\" solu\n",
    "\n",
    "Vinkkejä:\n",
    "* Käytä materiaaleista tuttua Tokenizer - luokkaa\n",
    "* Luo otsikoista samanpituiset sekvenssit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tehtävän toteutus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "answers_3_2"
    ]
   },
   "outputs": [],
   "source": [
    "# Tehtävän vastaukset. Huom! Älä muokkaa tätä solua, vaan aja se, kun olet suorittanut tehtävän. Sijoita results - muuttujaan funktion model.evaluate() tulos.\n",
    "# Muista määrittää model.compile() - funktioon seurattavaksi suureeksi metrics=['accuracy'], jotta näät, kuinka suuri osa neuroverkon ennustuksista on oikein.\n",
    "print(f\"Test Loss:{results[0]} Test Accuracy:{results[1]*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tehtävä 2.\n",
    "### Aihe: Aikasarjaennustaminen - Lämpötila ja sähkönkulutus\n",
    "2,5 pistettä\n",
    "\n",
    "Data - kansiossa tiedostoissa 'lampotila_2010.csv' ja 'sahkonkulutus_2010.csv' on vuoden 2010 tammikuun lämpötila Jyväskylän lentoasemalta ja koko Suomen sähkönkulutus. Tavoitteena on luoda neuroverkkomalli, joka ennustaa sähkönkulutuksen ja lämpötilan avulla tulevaa sähkönkulutusta.\n",
    "\n",
    "1. Ennusta 24 tunnin historiadatalla 24 tuntia eteenpäin\n",
    "2. Kouluta neuroverkko vuoden 2010 tammikuun datalla.\n",
    "3. Luo testidatasetti 'lampotila_2011.csv' ja 'sahkonkulutus_2011.csv' tiedostoista\n",
    "4. Ennusta mallilla vuoden 2011 tammikuun sähkönkulutusta. Piirrä oikeat arvot ja ennustetut arvot viivakaavioon.\n",
    "5. Aja \"Tehtävän vastaukset\" solu\n",
    "\n",
    "Vinkkejä:\n",
    "* Muuta aikasarja sekvenssimuotoon käyttäen multivariate_data - funktiota materiaaleista.\n",
    "    * Mitkä ovat muuttujia, joiden avulla ennustetaan, ja mitkä ovat ennustettavia arvoja?\n",
    "* Dataa on vähän, joten ennustustulokset saattavat olla huonoja\n",
    "    * Tärkeintä on, että idea on oikein\n",
    "    * Käytä Dropout - kerroksia ja vaihda LSTM - kerroksissa solujen määrää"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tehtävän toteutus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "answers_3_3"
    ]
   },
   "outputs": [],
   "source": [
    "# Tehtävän vastaukset.  Huom! Älä muokkaa tätä solua, vaan aja se, kun olet suorittanut tehtävän. \n",
    "# Luo tarvittavat osat viivakaavioon fig - muuttujaan matplotlib - kirjastoa käyttäen. Tuloksena pitäisi olla viivakaavio, jossa on piirrettynä oikeat arvot ja neuroverkon ennustukset.\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tehtävä 3.\n",
    "### Aihe: Autoenkooderit - Poikkeaman tunnistus \n",
    "2,5 pistettä\n",
    "\n",
    "Credit card fraud - datasetissä on 28 anonymisoitua muuttujaa, jonka perusteella voi arvioida, onko luottokorttitapahtuma aito vai huijaus, joka on myös datasetissä jokaiselle tapahtumalle luokiteltu.\n",
    "\n",
    "1. Lataa luottokorttihuijaus datasetti Kagglesta https://www.kaggle.com/mlg-ulb/creditcardfraud tai jos sinulla ei ole Kaggle tunnusta: https://student.labranet.jamk.fi/~korpjo/files/credit-card-fraud-detection.zip\n",
    "2. Jaa datasetti koulutus- ja testidatasettiin\n",
    "3. Luo autoenkooderimalli, jossa sisääntulevasta luottokorttitapahtumatiedoista tiivistetään pienin mahdollinen esitys, ja esitys luodaan takaisin luottokorttitapahtumatiedoksi\n",
    "4. Määritä koulutusdatan avulla raja-arvo virheelle, minkä ylittävät tapahtumat luokitellaan luottokorttihuijauksiksi\n",
    "5. Tutki numeerisesti tai visuaalisesti, kuinka hyvin raja-arvolla tunnistetaan poikkeamat testidatasetistä\n",
    "\n",
    "Vinkkejä:\n",
    "* Datasetissä on erittäin vähän poikkeamia oikeisiin tapahtumiin verrattuna. Käytä train_test_split funktion 'stratify' parametriä, jotta saat koulutus- ja testidatasetteihin oikean suhteen oikeita ja poikkeavia tapahtumia.\n",
    "* Viimeisessä kohdassa voit joko visualisoida poikkeamia Autoenkooderi - materiaalien tapaan kuvaajalla tai luomalla [sekaannusmatriisin](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) autoenkooderin ennusteista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tehtävän toteutus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tehtävän vastaukset. Käytä visualisaatiota tai osoita numeerisesti, kuinka monta poikkeamaa neuroverkkomalli huomasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tehtävä 4.\n",
    "### Aihe: Autoenkooderit - Kohinan poisto kuvasta\n",
    "2,5 pistettä\n",
    "\n",
    "Alla on luotu MNIST datasetistä \"korruptoitunut\" versio, jossa kuviin on lisätty kohinaa. Luo autoenkooderi, jolle syötetään suttuinen numero ja joka luo kuvan uudestaan puhtaana numerona.\n",
    "\n",
    "Todista autoenkooderin toiminta:\n",
    "1. Piirrä Matplotlibillä testidatasetistä suttuinen kuva (esim. test_X_noisy[10])\n",
    "2. Syötä suttuinen kuva autoenkooderille.\n",
    "3. Piirrä autoenkooderin ulostulona antama kuva.\n",
    "4. Aja \"Tehtävän vastaukset\" solu\n",
    "\n",
    "Vinkkejä:\n",
    "* Mieti, mikä muuttuja menee syötteenä autoenkooderiin ja mikä muuttuja on haluttu lopputulos?\n",
    "    * Suttuinen kuva -> autoenkooderi -> Selkeä kuva\n",
    "* Piirrät kuvat käyttäen matplotlib - kirjastoa\n",
    "    * Autoenkooderi materiaaleissa esimerkki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladataan tarvittavat kirjastot\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Puhdas MNIST datasetti, josta otetaan kymmenesosa kuvista datasettiin\n",
    "(train_X, _), (test_X, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_X, test_X = train_X[0:len(train_X) // 10], test_X[0:len(test_X) // 10]\n",
    "train_X, test_X = train_X / 255.0, test_X / 255.0\n",
    "train_X, test_X = train_X.reshape((train_X.shape[0],28,28,1)), test_X.reshape((test_X.shape[0],28,28,1))\n",
    "\n",
    "# Luodaan suttuisia kuvia MNIST datasetistä laittamalla kuviin kohinaa\n",
    "noise = np.random.normal(loc=0.5, scale=0.75, size=train_X.shape)\n",
    "train_X_noisy = train_X + noise\n",
    "noise = np.random.normal(loc=0.5, scale=0.75, size=test_X.shape)\n",
    "test_X_noisy = test_X + noise\n",
    "train_X_noisy = np.clip(train_X_noisy, 0., 1.) \n",
    "test_X_noisy = np.clip(test_X_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tehtävän toteutus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "answers_3_1"
    ]
   },
   "outputs": [],
   "source": [
    "# Tehtävän vastaukset.  Huom! Älä muokkaa tätä solua, vaan aja se, kun olet suorittanut tehtävän. \n",
    "# Syötä cleaned_img - muuttujaan autoenkooderin ulostulo. Muista muokata sitä ennen ulostulo takaisin 28x28 matriisiksi, jotta sen voi syöttää plt.imshow() funktiolle.\n",
    "plt.imshow(cleaned_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Tehtävä\n",
    "### Aihe: Twiitin klassifiointi - Positiivinen vai negatiivinen?\n",
    "2,5 pistettä\n",
    "\n",
    "Tämä on ylimääräinen tehtävä, jonka avulla voit saada muutaman lisäpisteen.\n",
    "\n",
    "Lataa datasetti osoitteesta https://student.labranet.jamk.fi/~korpjo/files/Sentiment-Analysis-Dataset.zip. Datasetissä on twiittejä, jotka on leimattu positiiviseksi (1) tai negatiiviseksi (0) Sentiment - sarakkeessa.\n",
    "\n",
    "Twiiteissä on paljon turhaa tavaraa, kuten linkkejä ja viittauksia muihin käyttäjiin @ - merkillä, jotka eivät auta tai haittaavat neuroverkkoja klassifioimaan twiittejä. Muokkaa datasettiä ja luo neuroverkkomalli, joka ennustaa, onko twiitti positiivinen vai negatiivinen. \n",
    "\n",
    "Jaa data koulutus- ja testidataan (80% koulutusdataa 20% testidataa jako) ja mittaa kuinka tarkka mallisi on testidatan avulla.\n",
    "\n",
    "Vinkkejä:\n",
    "* Tekstin esikäsittelyyn voi käyttää esim. TensorFlowin Tokenizer - luokkaa: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "* Viittauksia ja linkkejä ei välttämättä tarvitse poistaa, vaan ne voi korvata yleisesti jollakin merkkijonolla. Esim. \"http://iltalehti.fi\" -> \"link_to_website\" tai \"@elonmusk\" -> \"reference_to_user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tehtävän toteutus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2_gpu]",
   "language": "python",
   "name": "conda-env-tf2_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
